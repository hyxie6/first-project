
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "build/trainer_tutorial/nonb-01_basic_example.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_build_trainer_tutorial_nonb-01_basic_example.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_build_trainer_tutorial_nonb-01_basic_example.py:

Mastering Your Training Pipeline
==========================================================

.. GENERATED FROM PYTHON SOURCE LINES 25-28

Prerequest: Import packages and configure logging
----------------------------------------------------------


.. GENERATED FROM PYTHON SOURCE LINES 28-41

.. code-block:: Python


    import logging
    import os
    from typing import Any, Optional, Tuple

    import torch

    from robo_orchard_lab.utils import log_basic_config

    log_basic_config(level=logging.INFO)
    logger = logging.getLogger(__name__)









.. GENERATED FROM PYTHON SOURCE LINES 42-46

Part1: Using pydantic for configuration
---------------------------------------------------------
Our framework emphasizes configuration-driven training. Let's look at DatasetConfig


.. GENERATED FROM PYTHON SOURCE LINES 46-129

.. code-block:: Python


    from pydantic import Field
    from robo_orchard_core.utils.cli import SettingConfig
    from torch.utils.data import DataLoader, Dataset
    from torchvision import datasets, models, transforms


    class DatasetConfig(SettingConfig):
        """Configuration for the dataset.

        This is a example configuration for the ImageNet dataset.
        """

        data_root: Optional[str] = Field(
            description="Image dataset directory.", default=None
        )

        pipeline_test: bool = Field(
            description="Whether or not use dummy data for fast pipeline test.",
            default=False,
        )

        dummy_train_imgs: int = Field(
            description="Number of dummy training images.",
            default=1024,
        )

        dummy_val_imgs: int = Field(
            description="Number of dummy validation images.",
            default=256,
        )

        def __post_init__(self):
            if self.pipeline_test is False and self.data_root is None:
                raise ValueError(
                    "data_root must be specified when pipeline_test is False."
                )

        def get_dataset(self) -> Tuple[Dataset, Dataset]:
            if self.pipeline_test:
                train_dataset = datasets.FakeData(
                    self.dummy_train_imgs,
                    (3, 224, 224),
                    1000,
                    transforms.ToTensor(),
                )
                val_dataset = datasets.FakeData(
                    self.dummy_val_imgs, (3, 224, 224), 1000, transforms.ToTensor()
                )
            else:
                assert self.data_root is not None
                train_dataset = datasets.ImageFolder(
                    os.path.join(self.data_root, "train"),
                    transform=transforms.Compose(
                        [
                            transforms.RandomResizedCrop(224),
                            transforms.RandomHorizontalFlip(),
                            transforms.ToTensor(),
                            transforms.Normalize(
                                mean=[0.485, 0.456, 0.406],
                                std=[0.229, 0.224, 0.225],
                            ),
                        ]
                    ),
                )

                val_dataset = datasets.ImageFolder(
                    os.path.join(self.data_root, "val"),
                    transform=transforms.Compose(
                        [
                            transforms.Resize(256),
                            transforms.CenterCrop(224),
                            transforms.ToTensor(),
                            transforms.Normalize(
                                mean=[0.485, 0.456, 0.406],
                                std=[0.229, 0.224, 0.225],
                            ),
                        ]
                    ),
                )
            return train_dataset, val_dataset









.. GENERATED FROM PYTHON SOURCE LINES 130-133

DatasetConfig uses Pydantic Field to define parameters like data_root and pipeline_test.
The pipeline_test flag is crucial. If True, it uses FakeData for a quick test run without needing the actual ImageNet dataset.
get_dataset() method encapsulates the logic for creating train and validation datasets.

.. GENERATED FROM PYTHON SOURCE LINES 135-136

TrainerConfig, which nests DatasetConfig:

.. GENERATED FROM PYTHON SOURCE LINES 136-176

.. code-block:: Python



    class TrainerConfig(SettingConfig):
        """Configuration for the trainer.

        This is an example configuration for training a ResNet50 model
        on ImageNet. Only a few parameters are set here for demonstration
        purposes.
        """

        dataset: DatasetConfig = Field(
            description="Dataset configuration. Need to be set by user.",
        )

        batch_size: int = Field(
            description="Batch size for training.",
            default=128,
        )

        num_workers: int = Field(
            description="Number of workers for data loading.",
            default=4,
        )

        max_epoch: int = Field(
            description="Maximum number of epochs for training.",
            default=90,
        )

        workspace_root: str = Field(
            description="Workspace root directory.",
            default="./workspace/",
        )


    cfg = TrainerConfig(
        dataset=DatasetConfig(pipeline_test=True), max_epoch=5, num_workers=0
    )









.. GENERATED FROM PYTHON SOURCE LINES 177-178

These Pydantic models can also parsed from command-line arguments using ``pydantic_from_argparse(TrainerConfig, parser)``. This means you can override any setting from the CLI, e.g., ``--batch_size 64`` or even nested ones like ``--dataset.data_root /path/to/my/data``.

.. GENERATED FROM PYTHON SOURCE LINES 180-184

Part2: Understanding the Core trainer Components
---------------------------------------------------------
Let's dive into the specific components from robo_orchard_lab that make this work.


.. GENERATED FROM PYTHON SOURCE LINES 186-198

Accelerator: The Engine for Scale and Simplicity
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Accelerator from Hugging Face handles:

* Device Agnosticism: Runs your code on CPU, single GPU, multiple GPUs, or TPUs with minimal changes.

* Distributed Training: Automatically sets up distributed training if multiple GPUs are available.

* Mixed Precision: Can enable AMP for faster training and reduced memory.

* Checkpointing: Accelerator manage saving and loading checkpoints in an organized way.


.. GENERATED FROM PYTHON SOURCE LINES 198-212

.. code-block:: Python


    from accelerate import Accelerator
    from accelerate.utils import ProjectConfiguration

    accelerator = Accelerator(
        project_config=ProjectConfiguration(
            project_dir=cfg.workspace_root,
            logging_dir=os.path.join(cfg.workspace_root, "logs"),
            automatic_checkpoint_naming=True,
            total_limit=32,  # Max checkpoints to keep
        )
    )









.. GENERATED FROM PYTHON SOURCE LINES 213-225

Batch processor: Defining Per-Step Logic
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Instead of hard coding the forward pass and loss calculation within the trainer, we use a BatchProcessor.
MyBatchProcessor inherits from :py:class:`robo_orchard_lab.pipeline.batch_processor.simple.SimpleBatchProcessor`.

You define your loss function (here, CrossEntropyLoss) in ``__init__``.
``forward`` contains the logic for a single step: getting model output and calculating loss.
The need_backward flag allows this processor to be used for evaluation loops where backpropagation isn't needed.

.. note::
  Accelerator handles moving the model and batch to the correct device before forward is called by the trainer.


.. GENERATED FROM PYTHON SOURCE LINES 225-249

.. code-block:: Python


    from robo_orchard_lab.pipeline.batch_processor import SimpleBatchProcessor


    class MyBatchProcessor(SimpleBatchProcessor):
        def __init__(self, *args, **kwargs):
            super().__init__(*args, **kwargs)
            self.criterion = torch.nn.CrossEntropyLoss()  # Define your loss

        def forward(
            self,
            model: torch.nn.Module,
            batch: Tuple[torch.Tensor, torch.Tensor],
        ) -> Tuple[Any, Optional[torch.Tensor]]:
            # unpack batch by yourself
            images, target = batch

            # Accelerator has already moved batch to the correct device
            output = model(images)
            loss = self.criterion(output, target) if self.need_backward else None

            return output, loss  # Returns model output and loss









.. GENERATED FROM PYTHON SOURCE LINES 250-269

Hooks: Customizing your pipeline
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Hooks are the primary way to add custom behavior to the training or evaluation loop without modifying its source code.
They are called at specific points during training or evaluation (e.g., end of epoch, after a step).

Core Concepts of the ``PipelineHooks`` System

* :py:class:`robo_orchard_lab.pipeline.hooks.mixin.PipelineHookArgs`: A dataclass holding all relevant information (accelerator,
  epoch/step IDs, batch data, model outputs, loss, etc.) passed to each hook.
  This ensures hooks have a standardized, type-safe context.

* :py:class:`robo_orchard_lab.pipeline.hooks.mixin.PipelineHooksConfig`: The entire :py:class:`robo_orchard_lab.pipeline.hooks.mixin.PipelineHooks` setup,
  including which individual hooks are active and their parameters, can often be defined via Pydantic configurations.
  This offers great flexibility and reproducibility. For instance, a main
  experiment config might point to a :py:class:`robo_orchard_lab.pipeline.hooks.mixin.PipelineHooksConfig`,
  which in turn might specify a list of individual hook configurations (e.g.,
  :py:class:`robo_orchard_lab.pipeline.hooks.metric.MetricTrackerConfig`,
  :py:class:`robo_orchard_lab.pipeline.hooks.checkpoint.SaveCheckpointConfig`).


.. GENERATED FROM PYTHON SOURCE LINES 269-272

.. code-block:: Python


    hooks = []








.. GENERATED FROM PYTHON SOURCE LINES 273-285

MetricTracker: Track on performance
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
:py:class:`robo_orchard_lab.pipeline.hooks.metric.MetricTracker` is a specialized hook for handling metrics.
It takes a list of :py:class:`robo_orchard_lab.pipeline.hooks.metric.MetricEntry` objects. Each MetricEntry defines:

* names: How the metric will be logged.

* metric: An instance of a torchmetrics metric (or any compatible metric object).

:py:class:`robo_orchard_lab.pipeline.hooks.metric.MetricTracker` is an abstarct class, you should inherit it
and implement the :py:meth:`robo_orchard_lab.pipeline.hooks.metric.MetricTracker.update_metric` method, which is called by the trainer to update these metrics with batch outputs and targets.


.. GENERATED FROM PYTHON SOURCE LINES 285-330

.. code-block:: Python


    from torchmetrics import Accuracy as AccuracyMetric

    from robo_orchard_lab.pipeline.hooks import (
        MetricEntry,
        MetricTracker,
        MetricTrackerConfig,
    )


    class MyMetricTracker(MetricTracker):
        def update_metric(self, batch: Any, model_outputs: Any):
            _, targets = batch
            for metric_i in self.metrics:
                metric_i(model_outputs, targets)


    class MyMetricTrackerConfig(MetricTrackerConfig):
        """An example metric tracker config."""

        # note: bind MyMetricTracker
        class_type: type[MyMetricTracker] = MyMetricTracker


    metric_tracker = MyMetricTrackerConfig(
        metric_entrys=[
            MetricEntry(
                names=["top1_acc"],
                metric=AccuracyMetric(
                    task="multiclass", num_classes=1000, top_k=1
                ),
            ),
            MetricEntry(
                names=["top5_acc"],
                metric=AccuracyMetric(
                    task="multiclass", num_classes=1000, top_k=5
                ),
            ),
        ],
        step_log_freq=64,
        log_main_process_only=False,
    )

    hooks.append(metric_tracker)








.. GENERATED FROM PYTHON SOURCE LINES 331-337

StatsMonitor: Logging Training Vitals
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

:py:class:`robo_orchard_lab.pipeline.hooks.stats.StatsMonitor` monitors and logs statistics like learning rate, training speed (samples/sec), estimated time remaining, etc.
Its ``step_log_freq`` controls how often this information is printed or logged.


.. GENERATED FROM PYTHON SOURCE LINES 337-344

.. code-block:: Python


    from robo_orchard_lab.pipeline.hooks import StatsMonitorConfig

    stats = StatsMonitorConfig(step_log_freq=64)

    hooks.append(stats)








.. GENERATED FROM PYTHON SOURCE LINES 345-352

SaveCheckpoint: Saving Your Progress
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

:py:class:`robo_orchard_lab.pipeline.hooks.checkpoint.SaveCheckpointConfig` is responsible for triggering model checkpoint saves.
It calls :py:class:`acclerator.Accelerator.save_state()`` internally. ``save_step_freq`` defines how many training steps between checkpoints.
Resuming is handled by Accelerator


.. GENERATED FROM PYTHON SOURCE LINES 352-359

.. code-block:: Python


    from robo_orchard_lab.pipeline.hooks import SaveCheckpointConfig

    save_checkpoint = SaveCheckpointConfig(save_step_freq=1024)

    hooks.append(save_checkpoint)








.. GENERATED FROM PYTHON SOURCE LINES 360-376

(Advanced) Creating Your First Custom Hook
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

In many complex training scenarios, you might need to inject custom logic at various
points within the training loop (e.g., at the beginning/end of an epoch, or before/after
a training step). The ``robo_orchard_lab`` framework provides a powerful and flexible
Hook system based on ``PipelineHooks`` to achieve this without modifying the core
training engine.

This tutorial will guide you through:
1. Understanding the core components: ``PipelineHooksConfig``, ``PipelineHooks``, ``HookContext``, and ``PipelineHookArgs``.
2. Creating a custom hook class that bundles logging logic for different training stages.
3. Configuring and instantiating your custom hook.
4. (Simulated) Seeing how this hook would interact with a training engine.

Let's get started!

.. GENERATED FROM PYTHON SOURCE LINES 378-390

Implementing the Custom Hook: ``MyHook``
""""""""""""""""""""""""""""""""""""""""""""""""""""

Let's define ``MyHook``. It inherits from ``PipelineHooks``.
In its ``__init__`` method, it takes its configuration (``MyHookConfig``)
and registers its own internal methods as callbacks to different channels
using ``self.register_hook()`` and ``HookContext.from_callable()``.

``HookContext.from_callable(before=..., after=...)`` is a convenient way to create
a ``HookContext`` object where its ``on_enter`` method will call the ``before``
function, and its ``on_exit`` method will call the ``after`` function.


.. GENERATED FROM PYTHON SOURCE LINES 390-457

.. code-block:: Python


    from robo_orchard_lab.pipeline.hooks.mixin import (
        HookContext,
        PipelineHookArgs,
        PipelineHooks,
        PipelineHooksConfig,
    )


    class MyHook(PipelineHooks):
        """A custom hook that logs messages at the beginning and end of loops, epochs, and steps, based on configured frequencies."""

        def __init__(self, cfg: "MyHookConfig"):
            super().__init__()
            self.cfg = cfg

            # Register loop-level hooks
            self.register_hook(
                channel="on_loop",
                hook=HookContext.from_callable(before=self._on_loop_begin, after=self._on_loop_end)
            )

            # Register step-level hooks
            self.register_hook(
                channel="on_step",
                hook=HookContext.from_callable(
                    before=self._on_step_begin, after=self._on_step_end
                ),
            )

            # Register epoch-level hooks
            self.register_hook(
                channel="on_epoch",
                hook=HookContext.from_callable(
                    before=self._on_epoch_begin, after=self._on_epoch_end
                ),
            )

            logger.info(
                f"MyHook instance created with step_freq={self.cfg.log_step_freq}, epoch_freq={self.cfg.log_epoch_freq}"
            )

        def _on_loop_begin(self, args: PipelineHookArgs):
            logger.info("Begining loop")

        def _on_loop_end(self, args: PipelineHookArgs):
            logger.info("Ended loop")

        def _on_step_begin(self, args: PipelineHookArgs):
            # Note: step_id is 0-indexed. Adding 1 for 1-indexed frequency check.
            if (args.step_id + 1) % self.cfg.log_step_freq == 0:
                logger.info("Begining {}-th step".format(args.step_id))

        def _on_step_end(self, args: PipelineHookArgs):
            if (args.step_id + 1) % self.cfg.log_step_freq == 0:
                logger.info("Ended {}-th step".format(args.step_id))

        def _on_epoch_begin(self, args: PipelineHookArgs):
            # Note: epoch_id is 0-indexed. Adding 1 for 1-indexed frequency check.
            if (args.epoch_id + 1) % self.cfg.log_epoch_freq == 0:
                logger.info("Begining {}-th epoch".format(args.epoch_id))

        def _on_epoch_end(self, args: PipelineHookArgs):
            if (args.epoch_id + 1) % self.cfg.log_epoch_freq == 0:
                logger.info("Ended {}-th epoch".format(args.epoch_id))









.. GENERATED FROM PYTHON SOURCE LINES 458-466

Defining Your Custom Hook Configuration
""""""""""""""""""""""""""""""""""""""""""""""""""""

Then, we define a Pydantic configuration class for our custom hook.
This class will inherit from ``PipelineHooksConfig`` and specify our custom hook
class as its ``class_type``. It will also hold any parameters our hook needs,
like logging frequencies.


.. GENERATED FROM PYTHON SOURCE LINES 466-478

.. code-block:: Python


    class MyHookConfig(PipelineHooksConfig[MyHook]):
        class_type: type[MyHook] = MyHook
        log_step_freq: int = 5
        log_epoch_freq: int = 1


    my_hook = MyHookConfig()

    hooks.append(my_hook)









.. GENERATED FROM PYTHON SOURCE LINES 479-482

DataLoader, model, optimizer and learning rate scheduler
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


.. GENERATED FROM PYTHON SOURCE LINES 482-500

.. code-block:: Python


    from torch.optim import SGD
    from torch.optim.lr_scheduler import StepLR

    train_dataset, _ = cfg.dataset.get_dataset()
    train_dataloader = DataLoader(
        train_dataset,
        batch_size=cfg.batch_size,
        shuffle=True,
        num_workers=cfg.num_workers,
        pin_memory=False,
    )

    model = models.resnet50()

    optimizer = SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)
    lr_scheduler = StepLR(optimizer, step_size=30, gamma=0.1)








.. GENERATED FROM PYTHON SOURCE LINES 501-508

Part3: Orchestrating the Training
---------------------------------------------------------

:py:class:`robo_orchard_lab.pipeline.hook_based_trainer.HookBasedTrainer` is the heart of your training loop.
It takes all necessary PyTorch components (model, dataloader, optimizer, scheduler) and crucially,
the accelerator and a batch_processor. The hooks list allows for powerful customization, which we have explored before.


.. GENERATED FROM PYTHON SOURCE LINES 508-522

.. code-block:: Python


    from robo_orchard_lab.pipeline import HookBasedTrainer

    trainer = HookBasedTrainer(
        model=model,
        dataloader=train_dataloader,
        optimizer=optimizer,
        lr_scheduler=lr_scheduler,
        accelerator=accelerator,
        batch_processor=MyBatchProcessor(need_backward=True),
        max_epoch=cfg.max_epoch,
        hooks=hooks,
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Rank[0/1] 05/26/2025 20:05:29 INFO __main__:428 MyHook instance created with step_freq=5, epoch_freq=1




.. GENERATED FROM PYTHON SOURCE LINES 523-525

Show hooks


.. GENERATED FROM PYTHON SOURCE LINES 525-528

.. code-block:: Python


    print(trainer.hooks)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    <robo_orchard_lab.pipeline.hooks.mixin.PipelineHooks(
      hooks={
        on_loop: <robo_orchard_core.utils.hook.HookContextChannel(
          name=on_loop, 
          hooks=[
            0: <robo_orchard_core.utils.hook.HookContextFromCallable(
              name=None, 
              before=<FunctionInfo bound method MyMetricTracker(id=140617501111056)._on_loop_begin from ../../robo_orchard_lab/pipeline/hooks/metric.py:181>, 
              after=None)>,
            1: <robo_orchard_core.utils.hook.HookContextFromCallable(
              name=None, 
              before=<FunctionInfo bound method StatsMonitor(id=140617501110240)._on_loop_begin from ../../robo_orchard_lab/pipeline/hooks/stats.py:234>, 
              after=None)>,
            2: <robo_orchard_core.utils.hook.HookContextFromCallable(
              name=None, 
              before=<FunctionInfo bound method MyHook(id=140617761547664)._on_loop_begin from nonb-01_basic_example.py:432>, 
              after=<FunctionInfo bound method MyHook(id=140617761547664)._on_loop_end from nonb-01_basic_example.py:435>)>
          ])>, 
        on_epoch: <robo_orchard_core.utils.hook.HookContextChannel(
          name=on_epoch, 
          hooks=[
            0: <robo_orchard_core.utils.hook.HookContextFromCallable(
              name=None, 
              before=None, 
              after=<FunctionInfo bound method MyMetricTracker(id=140617501111056)._on_epoch_end from ../../robo_orchard_lab/pipeline/hooks/metric.py:233>)>,
            1: <robo_orchard_core.utils.hook.HookContextFromCallable(
              name=None, 
              before=<FunctionInfo bound method StatsMonitor(id=140617501110240)._on_epoch_begin from ../../robo_orchard_lab/pipeline/hooks/stats.py:316>, 
              after=<FunctionInfo bound method StatsMonitor(id=140617501110240)._on_epoch_end from ../../robo_orchard_lab/pipeline/hooks/stats.py:321>)>,
            2: <robo_orchard_core.utils.hook.HookContextFromCallable(
              name=None, 
              before=None, 
              after=<FunctionInfo bound method SaveCheckpoint(id=140617501101504)._on_epoch_end from ../../robo_orchard_lab/pipeline/hooks/checkpoint.py:116>)>,
            3: <robo_orchard_core.utils.hook.HookContextFromCallable(
              name=None, 
              before=<FunctionInfo bound method MyHook(id=140617761547664)._on_epoch_begin from nonb-01_basic_example.py:447>, 
              after=<FunctionInfo bound method MyHook(id=140617761547664)._on_epoch_end from nonb-01_basic_example.py:452>)>
          ])>, 
        on_step: <robo_orchard_core.utils.hook.HookContextChannel(
          name=on_step, 
          hooks=[
            0: <robo_orchard_core.utils.hook.HookContextFromCallable(
              name=None, 
              before=None, 
              after=<FunctionInfo bound method OptimizerHook(id=140617491416160)._optimizer_step from ../../robo_orchard_lab/pipeline/hooks/optimizer.py:45>)>,
            1: <robo_orchard_core.utils.hook.HookContextFromCallable(
              name=None, 
              before=None, 
              after=<FunctionInfo bound method MyMetricTracker(id=140617501111056)._on_step_end from ../../robo_orchard_lab/pipeline/hooks/metric.py:205>)>,
            2: <robo_orchard_core.utils.hook.HookContextFromCallable(
              name=None, 
              before=<FunctionInfo bound method StatsMonitor(id=140617501110240)._on_step_begin from ../../robo_orchard_lab/pipeline/hooks/stats.py:245>, 
              after=<FunctionInfo bound method StatsMonitor(id=140617501110240)._on_step_end from ../../robo_orchard_lab/pipeline/hooks/stats.py:249>)>,
            3: <robo_orchard_core.utils.hook.HookContextFromCallable(
              name=None, 
              before=None, 
              after=<FunctionInfo bound method SaveCheckpoint(id=140617501101504)._on_step_end from ../../robo_orchard_lab/pipeline/hooks/checkpoint.py:88>)>,
            4: <robo_orchard_core.utils.hook.HookContextFromCallable(
              name=None, 
              before=<FunctionInfo bound method MyHook(id=140617761547664)._on_step_begin from nonb-01_basic_example.py:438>, 
              after=<FunctionInfo bound method MyHook(id=140617761547664)._on_step_end from nonb-01_basic_example.py:443>)>
          ])>, 
        on_batch: <robo_orchard_core.utils.hook.HookContextChannel(
          name=on_batch, 
          hooks=[
            0: <robo_orchard_core.utils.hook.HookContextFromCallable(
              name=None, 
              before=None, 
              after=<FunctionInfo bound method MyMetricTracker(id=140617501111056)._on_batch_end from ../../robo_orchard_lab/pipeline/hooks/metric.py:194>)>
          ])>, 
      })>




.. GENERATED FROM PYTHON SOURCE LINES 529-531

Begin training


.. GENERATED FROM PYTHON SOURCE LINES 531-534

.. code-block:: Python


    trainer()





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Rank[0/1] 05/26/2025 20:05:29 INFO robo_orchard_lab.pipeline.hook_based_trainer:323 
    ==================================================BEGIN TRAINING==================================================
    Rank[0/1] 05/26/2025 20:05:29 INFO robo_orchard_lab.pipeline.hook_based_trainer:327 Start training loop from epoch 0 and step 0
    Rank[0/1] 05/26/2025 20:05:29 INFO __main__:433 Begining loop
    Rank[0/1] 05/26/2025 20:05:29 INFO __main__:450 Begining 0-th epoch
    Rank[0/1] 05/26/2025 20:05:33 INFO __main__:441 Begining 4-th step
    Rank[0/1] 05/26/2025 20:05:33 INFO __main__:445 Ended 4-th step
    Rank[0/1] 05/26/2025 20:05:35 INFO robo_orchard_lab.pipeline.hooks.metric:179 Epoch[0]: top1_acc[tensor(0.0020, device='cuda:0')] top5_acc[tensor(0.0078, device='cuda:0')] 
    Rank[0/1] 05/26/2025 20:05:35 INFO robo_orchard_lab.pipeline.hooks.stats:394 Epoch[0] completed. Training Speed: 164.57 samples/sec across all devices. Epoch Time: 6.22 sec.   Average Epoch Time: 6.22 sec.   Average Step Time: 0.78 sec.    Estimated Remaining Time: 0:00:24.      Learning Rate: 1.00000e-01.     
    Rank[0/1] 05/26/2025 20:05:35 INFO accelerate.accelerator:3022 Saving current state to ./workspace/checkpoints/checkpoint_0
    Rank[0/1] 05/26/2025 20:05:35 INFO accelerate.checkpointing:105 Model weights saved in workspace/checkpoints/checkpoint_0/model.safetensors
    Rank[0/1] 05/26/2025 20:05:35 INFO accelerate.checkpointing:105 Model weights saved in workspace/checkpoints/checkpoint_0/model_1.safetensors
    Rank[0/1] 05/26/2025 20:05:35 INFO accelerate.checkpointing:112 Optimizer state saved in workspace/checkpoints/checkpoint_0/optimizer.bin
    Rank[0/1] 05/26/2025 20:05:35 INFO accelerate.checkpointing:119 Scheduler state saved in workspace/checkpoints/checkpoint_0/scheduler.bin
    Rank[0/1] 05/26/2025 20:05:35 INFO accelerate.checkpointing:136 Sampler state for dataloader 0 saved in workspace/checkpoints/checkpoint_0/sampler.bin
    Rank[0/1] 05/26/2025 20:05:36 INFO accelerate.checkpointing:161 Random states saved in workspace/checkpoints/checkpoint_0/random_states_0.pkl
    Rank[0/1] 05/26/2025 20:05:36 INFO accelerate.checkpointing:295 Saving the state of TrainerProgressState to workspace/checkpoints/checkpoint_0/custom_checkpoint_0.pkl
    Rank[0/1] 05/26/2025 20:05:36 INFO robo_orchard_lab.pipeline.hooks.checkpoint:137 Save checkpoint at the end of epoch 0 to workspace/checkpoints/checkpoint_0
    Rank[0/1] 05/26/2025 20:05:36 INFO __main__:454 Ended 0-th epoch
    Rank[0/1] 05/26/2025 20:05:36 INFO __main__:450 Begining 1-th epoch
    Rank[0/1] 05/26/2025 20:05:39 INFO __main__:441 Begining 4-th step
    Rank[0/1] 05/26/2025 20:05:39 INFO __main__:445 Ended 4-th step
    Rank[0/1] 05/26/2025 20:05:41 INFO robo_orchard_lab.pipeline.hooks.metric:179 Epoch[1]: top1_acc[tensor(0.0020, device='cuda:0')] top5_acc[tensor(0.0098, device='cuda:0')] 
    Rank[0/1] 05/26/2025 20:05:41 INFO robo_orchard_lab.pipeline.hooks.stats:394 Epoch[1] completed. Training Speed: 185.71 samples/sec across all devices. Epoch Time: 5.51 sec.   Average Epoch Time: 5.51 sec.   Average Step Time: 0.69 sec.    Estimated Remaining Time: 0:00:18.      Learning Rate: 1.00000e-01.     
    Rank[0/1] 05/26/2025 20:05:41 INFO accelerate.accelerator:3022 Saving current state to ./workspace/checkpoints/checkpoint_1
    Rank[0/1] 05/26/2025 20:05:41 INFO accelerate.checkpointing:105 Model weights saved in workspace/checkpoints/checkpoint_1/model.safetensors
    Rank[0/1] 05/26/2025 20:05:41 INFO accelerate.checkpointing:105 Model weights saved in workspace/checkpoints/checkpoint_1/model_1.safetensors
    Rank[0/1] 05/26/2025 20:05:41 INFO accelerate.checkpointing:112 Optimizer state saved in workspace/checkpoints/checkpoint_1/optimizer.bin
    Rank[0/1] 05/26/2025 20:05:41 INFO accelerate.checkpointing:119 Scheduler state saved in workspace/checkpoints/checkpoint_1/scheduler.bin
    Rank[0/1] 05/26/2025 20:05:41 INFO accelerate.checkpointing:136 Sampler state for dataloader 0 saved in workspace/checkpoints/checkpoint_1/sampler.bin
    Rank[0/1] 05/26/2025 20:05:41 INFO accelerate.checkpointing:161 Random states saved in workspace/checkpoints/checkpoint_1/random_states_0.pkl
    Rank[0/1] 05/26/2025 20:05:41 INFO accelerate.checkpointing:295 Saving the state of TrainerProgressState to workspace/checkpoints/checkpoint_1/custom_checkpoint_0.pkl
    Rank[0/1] 05/26/2025 20:05:41 INFO robo_orchard_lab.pipeline.hooks.checkpoint:137 Save checkpoint at the end of epoch 1 to workspace/checkpoints/checkpoint_1
    Rank[0/1] 05/26/2025 20:05:41 INFO __main__:454 Ended 1-th epoch
    Rank[0/1] 05/26/2025 20:05:41 INFO __main__:450 Begining 2-th epoch
    Rank[0/1] 05/26/2025 20:05:45 INFO __main__:441 Begining 4-th step
    Rank[0/1] 05/26/2025 20:05:45 INFO __main__:445 Ended 4-th step
    Rank[0/1] 05/26/2025 20:05:47 INFO robo_orchard_lab.pipeline.hooks.metric:179 Epoch[2]: top1_acc[tensor(0.0010, device='cuda:0')] top5_acc[tensor(0.0098, device='cuda:0')] 
    Rank[0/1] 05/26/2025 20:05:47 INFO robo_orchard_lab.pipeline.hooks.stats:394 Epoch[2] completed. Training Speed: 190.39 samples/sec across all devices. Epoch Time: 5.38 sec.   Average Epoch Time: 5.38 sec.   Average Step Time: 0.67 sec.    Estimated Remaining Time: 0:00:11.      Learning Rate: 1.00000e-01.     
    Rank[0/1] 05/26/2025 20:05:47 INFO accelerate.accelerator:3022 Saving current state to ./workspace/checkpoints/checkpoint_2
    Rank[0/1] 05/26/2025 20:05:47 INFO accelerate.checkpointing:105 Model weights saved in workspace/checkpoints/checkpoint_2/model.safetensors
    Rank[0/1] 05/26/2025 20:05:47 INFO accelerate.checkpointing:105 Model weights saved in workspace/checkpoints/checkpoint_2/model_1.safetensors
    Rank[0/1] 05/26/2025 20:05:47 INFO accelerate.checkpointing:112 Optimizer state saved in workspace/checkpoints/checkpoint_2/optimizer.bin
    Rank[0/1] 05/26/2025 20:05:47 INFO accelerate.checkpointing:119 Scheduler state saved in workspace/checkpoints/checkpoint_2/scheduler.bin
    Rank[0/1] 05/26/2025 20:05:47 INFO accelerate.checkpointing:136 Sampler state for dataloader 0 saved in workspace/checkpoints/checkpoint_2/sampler.bin
    Rank[0/1] 05/26/2025 20:05:47 INFO accelerate.checkpointing:161 Random states saved in workspace/checkpoints/checkpoint_2/random_states_0.pkl
    Rank[0/1] 05/26/2025 20:05:47 INFO accelerate.checkpointing:295 Saving the state of TrainerProgressState to workspace/checkpoints/checkpoint_2/custom_checkpoint_0.pkl
    Rank[0/1] 05/26/2025 20:05:47 INFO robo_orchard_lab.pipeline.hooks.checkpoint:137 Save checkpoint at the end of epoch 2 to workspace/checkpoints/checkpoint_2
    Rank[0/1] 05/26/2025 20:05:47 INFO __main__:454 Ended 2-th epoch
    Rank[0/1] 05/26/2025 20:05:47 INFO __main__:450 Begining 3-th epoch
    Rank[0/1] 05/26/2025 20:05:51 INFO __main__:441 Begining 4-th step
    Rank[0/1] 05/26/2025 20:05:51 INFO __main__:445 Ended 4-th step
    Rank[0/1] 05/26/2025 20:05:53 INFO robo_orchard_lab.pipeline.hooks.metric:179 Epoch[3]: top1_acc[tensor(0.0029, device='cuda:0')] top5_acc[tensor(0.0176, device='cuda:0')] 
    Rank[0/1] 05/26/2025 20:05:53 INFO robo_orchard_lab.pipeline.hooks.stats:394 Epoch[3] completed. Training Speed: 189.21 samples/sec across all devices. Epoch Time: 5.41 sec.   Average Epoch Time: 5.41 sec.   Average Step Time: 0.68 sec.    Estimated Remaining Time: 0:00:05.      Learning Rate: 1.00000e-02.     
    Rank[0/1] 05/26/2025 20:05:53 INFO accelerate.accelerator:3022 Saving current state to ./workspace/checkpoints/checkpoint_3
    Rank[0/1] 05/26/2025 20:05:53 INFO accelerate.checkpointing:105 Model weights saved in workspace/checkpoints/checkpoint_3/model.safetensors
    Rank[0/1] 05/26/2025 20:05:53 INFO accelerate.checkpointing:105 Model weights saved in workspace/checkpoints/checkpoint_3/model_1.safetensors
    Rank[0/1] 05/26/2025 20:05:53 INFO accelerate.checkpointing:112 Optimizer state saved in workspace/checkpoints/checkpoint_3/optimizer.bin
    Rank[0/1] 05/26/2025 20:05:53 INFO accelerate.checkpointing:119 Scheduler state saved in workspace/checkpoints/checkpoint_3/scheduler.bin
    Rank[0/1] 05/26/2025 20:05:53 INFO accelerate.checkpointing:136 Sampler state for dataloader 0 saved in workspace/checkpoints/checkpoint_3/sampler.bin
    Rank[0/1] 05/26/2025 20:05:53 INFO accelerate.checkpointing:161 Random states saved in workspace/checkpoints/checkpoint_3/random_states_0.pkl
    Rank[0/1] 05/26/2025 20:05:53 INFO accelerate.checkpointing:295 Saving the state of TrainerProgressState to workspace/checkpoints/checkpoint_3/custom_checkpoint_0.pkl
    Rank[0/1] 05/26/2025 20:05:53 INFO robo_orchard_lab.pipeline.hooks.checkpoint:137 Save checkpoint at the end of epoch 3 to workspace/checkpoints/checkpoint_3
    Rank[0/1] 05/26/2025 20:05:53 INFO __main__:454 Ended 3-th epoch
    Rank[0/1] 05/26/2025 20:05:53 INFO __main__:450 Begining 4-th epoch
    Rank[0/1] 05/26/2025 20:05:57 INFO __main__:441 Begining 4-th step
    Rank[0/1] 05/26/2025 20:05:57 INFO __main__:445 Ended 4-th step
    Rank[0/1] 05/26/2025 20:05:58 INFO robo_orchard_lab.pipeline.hooks.metric:179 Epoch[4]: top1_acc[tensor(0.0059, device='cuda:0')] top5_acc[tensor(0.0205, device='cuda:0')] 
    Rank[0/1] 05/26/2025 20:05:58 INFO robo_orchard_lab.pipeline.hooks.stats:394 Epoch[4] completed. Training Speed: 186.09 samples/sec across all devices. Epoch Time: 5.50 sec.   Average Epoch Time: 5.50 sec.   Average Step Time: 0.69 sec.    Estimated Remaining Time: 0:00:00.      Learning Rate: 1.00000e-02.     
    Rank[0/1] 05/26/2025 20:05:58 INFO accelerate.accelerator:3022 Saving current state to ./workspace/checkpoints/checkpoint_4
    Rank[0/1] 05/26/2025 20:05:59 INFO accelerate.checkpointing:105 Model weights saved in workspace/checkpoints/checkpoint_4/model.safetensors
    Rank[0/1] 05/26/2025 20:05:59 INFO accelerate.checkpointing:105 Model weights saved in workspace/checkpoints/checkpoint_4/model_1.safetensors
    Rank[0/1] 05/26/2025 20:05:59 INFO accelerate.checkpointing:112 Optimizer state saved in workspace/checkpoints/checkpoint_4/optimizer.bin
    Rank[0/1] 05/26/2025 20:05:59 INFO accelerate.checkpointing:119 Scheduler state saved in workspace/checkpoints/checkpoint_4/scheduler.bin
    Rank[0/1] 05/26/2025 20:05:59 INFO accelerate.checkpointing:136 Sampler state for dataloader 0 saved in workspace/checkpoints/checkpoint_4/sampler.bin
    Rank[0/1] 05/26/2025 20:05:59 INFO accelerate.checkpointing:161 Random states saved in workspace/checkpoints/checkpoint_4/random_states_0.pkl
    Rank[0/1] 05/26/2025 20:05:59 INFO accelerate.checkpointing:295 Saving the state of TrainerProgressState to workspace/checkpoints/checkpoint_4/custom_checkpoint_0.pkl
    Rank[0/1] 05/26/2025 20:05:59 INFO robo_orchard_lab.pipeline.hooks.checkpoint:137 Save checkpoint at the end of epoch 4 to workspace/checkpoints/checkpoint_4
    Rank[0/1] 05/26/2025 20:05:59 INFO __main__:454 Ended 4-th epoch
    Rank[0/1] 05/26/2025 20:05:59 INFO __main__:436 Ended loop
    Rank[0/1] 05/26/2025 20:05:59 INFO robo_orchard_lab.pipeline.hook_based_trainer:396 
    ==================================================FINISH TRAINING==================================================




.. GENERATED FROM PYTHON SOURCE LINES 535-536

All the checkpoints is saved to ``cfg.workspace``

.. GENERATED FROM PYTHON SOURCE LINES 536-540

.. code-block:: Python


    import subprocess

    print(subprocess.check_output(["tree", cfg.workspace_root]).decode())




.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    ./workspace/
    └── checkpoints
        ├── checkpoint_0
        │   ├── custom_checkpoint_0.pkl
        │   ├── model_1.safetensors
        │   ├── model.safetensors
        │   ├── optimizer.bin
        │   ├── random_states_0.pkl
        │   └── scheduler.bin
        ├── checkpoint_1
        │   ├── custom_checkpoint_0.pkl
        │   ├── model_1.safetensors
        │   ├── model.safetensors
        │   ├── optimizer.bin
        │   ├── random_states_0.pkl
        │   └── scheduler.bin
        ├── checkpoint_2
        │   ├── custom_checkpoint_0.pkl
        │   ├── model_1.safetensors
        │   ├── model.safetensors
        │   ├── optimizer.bin
        │   ├── random_states_0.pkl
        │   └── scheduler.bin
        ├── checkpoint_3
        │   ├── custom_checkpoint_0.pkl
        │   ├── model_1.safetensors
        │   ├── model.safetensors
        │   ├── optimizer.bin
        │   ├── random_states_0.pkl
        │   └── scheduler.bin
        └── checkpoint_4
            ├── custom_checkpoint_0.pkl
            ├── model_1.safetensors
            ├── model.safetensors
            ├── optimizer.bin
            ├── random_states_0.pkl
            └── scheduler.bin

    6 directories, 30 files






.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 30.974 seconds)


.. _sphx_glr_download_build_trainer_tutorial_nonb-01_basic_example.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: nonb-01_basic_example.ipynb <nonb-01_basic_example.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: nonb-01_basic_example.py <nonb-01_basic_example.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: nonb-01_basic_example.zip <nonb-01_basic_example.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
