{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Mastering Your Training Pipeline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prerequest: Import packages and configure logging\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import logging\nimport os\nfrom typing import Any, Optional, Tuple\n\nimport torch\n\nfrom robo_orchard_lab.utils import log_basic_config\n\nlog_basic_config(level=logging.INFO)\nlogger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part1: Using pydantic for configuration\nOur framework emphasizes configuration-driven training. Let's look at DatasetConfig\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pydantic import Field\nfrom robo_orchard_core.utils.cli import SettingConfig\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import datasets, models, transforms\n\n\nclass DatasetConfig(SettingConfig):\n    \"\"\"Configuration for the dataset.\n\n    This is a example configuration for the ImageNet dataset.\n    \"\"\"\n\n    data_root: Optional[str] = Field(\n        description=\"Image dataset directory.\", default=None\n    )\n\n    pipeline_test: bool = Field(\n        description=\"Whether or not use dummy data for fast pipeline test.\",\n        default=False,\n    )\n\n    dummy_train_imgs: int = Field(\n        description=\"Number of dummy training images.\",\n        default=1024,\n    )\n\n    dummy_val_imgs: int = Field(\n        description=\"Number of dummy validation images.\",\n        default=256,\n    )\n\n    def __post_init__(self):\n        if self.pipeline_test is False and self.data_root is None:\n            raise ValueError(\n                \"data_root must be specified when pipeline_test is False.\"\n            )\n\n    def get_dataset(self) -> Tuple[Dataset, Dataset]:\n        if self.pipeline_test:\n            train_dataset = datasets.FakeData(\n                self.dummy_train_imgs,\n                (3, 224, 224),\n                1000,\n                transforms.ToTensor(),\n            )\n            val_dataset = datasets.FakeData(\n                self.dummy_val_imgs, (3, 224, 224), 1000, transforms.ToTensor()\n            )\n        else:\n            assert self.data_root is not None\n            train_dataset = datasets.ImageFolder(\n                os.path.join(self.data_root, \"train\"),\n                transform=transforms.Compose(\n                    [\n                        transforms.RandomResizedCrop(224),\n                        transforms.RandomHorizontalFlip(),\n                        transforms.ToTensor(),\n                        transforms.Normalize(\n                            mean=[0.485, 0.456, 0.406],\n                            std=[0.229, 0.224, 0.225],\n                        ),\n                    ]\n                ),\n            )\n\n            val_dataset = datasets.ImageFolder(\n                os.path.join(self.data_root, \"val\"),\n                transform=transforms.Compose(\n                    [\n                        transforms.Resize(256),\n                        transforms.CenterCrop(224),\n                        transforms.ToTensor(),\n                        transforms.Normalize(\n                            mean=[0.485, 0.456, 0.406],\n                            std=[0.229, 0.224, 0.225],\n                        ),\n                    ]\n                ),\n            )\n        return train_dataset, val_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "DatasetConfig uses Pydantic Field to define parameters like data_root and pipeline_test.\nThe pipeline_test flag is crucial. If True, it uses FakeData for a quick test run without needing the actual ImageNet dataset.\nget_dataset() method encapsulates the logic for creating train and validation datasets.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "TrainerConfig, which nests DatasetConfig:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class TrainerConfig(SettingConfig):\n    \"\"\"Configuration for the trainer.\n\n    This is an example configuration for training a ResNet50 model\n    on ImageNet. Only a few parameters are set here for demonstration\n    purposes.\n    \"\"\"\n\n    dataset: DatasetConfig = Field(\n        description=\"Dataset configuration. Need to be set by user.\",\n    )\n\n    batch_size: int = Field(\n        description=\"Batch size for training.\",\n        default=128,\n    )\n\n    num_workers: int = Field(\n        description=\"Number of workers for data loading.\",\n        default=4,\n    )\n\n    max_epoch: int = Field(\n        description=\"Maximum number of epochs for training.\",\n        default=90,\n    )\n\n    workspace_root: str = Field(\n        description=\"Workspace root directory.\",\n        default=\"./workspace/\",\n    )\n\n\ncfg = TrainerConfig(\n    dataset=DatasetConfig(pipeline_test=True), max_epoch=5, num_workers=0\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These Pydantic models can also parsed from command-line arguments using ``pydantic_from_argparse(TrainerConfig, parser)``. This means you can override any setting from the CLI, e.g., ``--batch_size 64`` or even nested ones like ``--dataset.data_root /path/to/my/data``.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part2: Understanding the Core trainer Components\nLet's dive into the specific components from robo_orchard_lab that make this work.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Accelerator: The Engine for Scale and Simplicity\nAccelerator from Hugging Face handles:\n\n* Device Agnosticism: Runs your code on CPU, single GPU, multiple GPUs, or TPUs with minimal changes.\n\n* Distributed Training: Automatically sets up distributed training if multiple GPUs are available.\n\n* Mixed Precision: Can enable AMP for faster training and reduced memory.\n\n* Checkpointing: Accelerator manage saving and loading checkpoints in an organized way.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from accelerate import Accelerator\nfrom accelerate.utils import ProjectConfiguration\n\naccelerator = Accelerator(\n    project_config=ProjectConfiguration(\n        project_dir=cfg.workspace_root,\n        logging_dir=os.path.join(cfg.workspace_root, \"logs\"),\n        automatic_checkpoint_naming=True,\n        total_limit=32,  # Max checkpoints to keep\n    )\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Batch processor: Defining Per-Step Logic\nInstead of hard coding the forward pass and loss calculation within the trainer, we use a BatchProcessor.\nMyBatchProcessor inherits from :py:class:`robo_orchard_lab.pipeline.batch_processor.simple.SimpleBatchProcessor`.\n\nYou define your loss function (here, CrossEntropyLoss) in ``__init__``.\n``forward`` contains the logic for a single step: getting model output and calculating loss.\nThe need_backward flag allows this processor to be used for evaluation loops where backpropagation isn't needed.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>Accelerator handles moving the model and batch to the correct device before forward is called by the trainer.</p></div>\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from robo_orchard_lab.pipeline.batch_processor import SimpleBatchProcessor\n\n\nclass MyBatchProcessor(SimpleBatchProcessor):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.criterion = torch.nn.CrossEntropyLoss()  # Define your loss\n\n    def forward(\n        self,\n        model: torch.nn.Module,\n        batch: Tuple[torch.Tensor, torch.Tensor],\n    ) -> Tuple[Any, Optional[torch.Tensor]]:\n        # unpack batch by yourself\n        images, target = batch\n\n        # Accelerator has already moved batch to the correct device\n        output = model(images)\n        loss = self.criterion(output, target) if self.need_backward else None\n\n        return output, loss  # Returns model output and loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hooks: Customizing your pipeline\nHooks are the primary way to add custom behavior to the training or evaluation loop without modifying its source code.\nThey are called at specific points during training or evaluation (e.g., end of epoch, after a step).\n\nCore Concepts of the ``PipelineHooks`` System\n\n* :py:class:`robo_orchard_lab.pipeline.hooks.mixin.PipelineHookArgs`: A dataclass holding all relevant information (accelerator,\n  epoch/step IDs, batch data, model outputs, loss, etc.) passed to each hook.\n  This ensures hooks have a standardized, type-safe context.\n\n* :py:class:`robo_orchard_lab.pipeline.hooks.mixin.PipelineHooksConfig`: The entire :py:class:`robo_orchard_lab.pipeline.hooks.mixin.PipelineHooks` setup,\n  including which individual hooks are active and their parameters, can often be defined via Pydantic configurations.\n  This offers great flexibility and reproducibility. For instance, a main\n  experiment config might point to a :py:class:`robo_orchard_lab.pipeline.hooks.mixin.PipelineHooksConfig`,\n  which in turn might specify a list of individual hook configurations (e.g.,\n  :py:class:`robo_orchard_lab.pipeline.hooks.metric.MetricTrackerConfig`,\n  :py:class:`robo_orchard_lab.pipeline.hooks.checkpoint.SaveCheckpointConfig`).\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "hooks = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### MetricTracker: Track on performance\n:py:class:`robo_orchard_lab.pipeline.hooks.metric.MetricTracker` is a specialized hook for handling metrics.\nIt takes a list of :py:class:`robo_orchard_lab.pipeline.hooks.metric.MetricEntry` objects. Each MetricEntry defines:\n\n* names: How the metric will be logged.\n\n* metric: An instance of a torchmetrics metric (or any compatible metric object).\n\n:py:class:`robo_orchard_lab.pipeline.hooks.metric.MetricTracker` is an abstarct class, you should inherit it\nand implement the :py:meth:`robo_orchard_lab.pipeline.hooks.metric.MetricTracker.update_metric` method, which is called by the trainer to update these metrics with batch outputs and targets.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torchmetrics import Accuracy as AccuracyMetric\n\nfrom robo_orchard_lab.pipeline.hooks import (\n    MetricEntry,\n    MetricTracker,\n    MetricTrackerConfig,\n)\n\n\nclass MyMetricTracker(MetricTracker):\n    def update_metric(self, batch: Any, model_outputs: Any):\n        _, targets = batch\n        for metric_i in self.metrics:\n            metric_i(model_outputs, targets)\n\n\nclass MyMetricTrackerConfig(MetricTrackerConfig):\n    \"\"\"An example metric tracker config.\"\"\"\n\n    # note: bind MyMetricTracker\n    class_type: type[MyMetricTracker] = MyMetricTracker\n\n\nmetric_tracker = MyMetricTrackerConfig(\n    metric_entrys=[\n        MetricEntry(\n            names=[\"top1_acc\"],\n            metric=AccuracyMetric(\n                task=\"multiclass\", num_classes=1000, top_k=1\n            ),\n        ),\n        MetricEntry(\n            names=[\"top5_acc\"],\n            metric=AccuracyMetric(\n                task=\"multiclass\", num_classes=1000, top_k=5\n            ),\n        ),\n    ],\n    step_log_freq=64,\n    log_main_process_only=False,\n)\n\nhooks.append(metric_tracker)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### StatsMonitor: Logging Training Vitals\n\n:py:class:`robo_orchard_lab.pipeline.hooks.stats.StatsMonitor` monitors and logs statistics like learning rate, training speed (samples/sec), estimated time remaining, etc.\nIts ``step_log_freq`` controls how often this information is printed or logged.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from robo_orchard_lab.pipeline.hooks import StatsMonitorConfig\n\nstats = StatsMonitorConfig(step_log_freq=64)\n\nhooks.append(stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### SaveCheckpoint: Saving Your Progress\n\n:py:class:`robo_orchard_lab.pipeline.hooks.checkpoint.SaveCheckpointConfig` is responsible for triggering model checkpoint saves.\nIt calls :py:class:`acclerator.Accelerator.save_state()`` internally. ``save_step_freq`` defines how many training steps between checkpoints.\nResuming is handled by Accelerator\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from robo_orchard_lab.pipeline.hooks import SaveCheckpointConfig\n\nsave_checkpoint = SaveCheckpointConfig(save_step_freq=1024)\n\nhooks.append(save_checkpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### (Advanced) Creating Your First Custom Hook\n\nIn many complex training scenarios, you might need to inject custom logic at various\npoints within the training loop (e.g., at the beginning/end of an epoch, or before/after\na training step). The ``robo_orchard_lab`` framework provides a powerful and flexible\nHook system based on ``PipelineHooks`` to achieve this without modifying the core\ntraining engine.\n\nThis tutorial will guide you through:\n1. Understanding the core components: ``PipelineHooksConfig``, ``PipelineHooks``, ``HookContext``, and ``PipelineHookArgs``.\n2. Creating a custom hook class that bundles logging logic for different training stages.\n3. Configuring and instantiating your custom hook.\n4. (Simulated) Seeing how this hook would interact with a training engine.\n\nLet's get started!\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Implementing the Custom Hook: ``MyHook``\n\nLet's define ``MyHook``. It inherits from ``PipelineHooks``.\nIn its ``__init__`` method, it takes its configuration (``MyHookConfig``)\nand registers its own internal methods as callbacks to different channels\nusing ``self.register_hook()`` and ``HookContext.from_callable()``.\n\n``HookContext.from_callable(before=..., after=...)`` is a convenient way to create\na ``HookContext`` object where its ``on_enter`` method will call the ``before``\nfunction, and its ``on_exit`` method will call the ``after`` function.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from robo_orchard_lab.pipeline.hooks.mixin import (\n    HookContext,\n    PipelineHookArgs,\n    PipelineHooks,\n    PipelineHooksConfig,\n)\n\n\nclass MyHook(PipelineHooks):\n    \"\"\"A custom hook that logs messages at the beginning and end of loops, epochs, and steps, based on configured frequencies.\"\"\"\n\n    def __init__(self, cfg: \"MyHookConfig\"):\n        super().__init__()\n        self.cfg = cfg\n\n        # Register loop-level hooks\n        self.register_hook(\n            channel=\"on_loop\",\n            hook=HookContext.from_callable(\n                before=self._on_loop_begin, after=self._on_loop_end\n            ),\n        )\n\n        # Register step-level hooks\n        self.register_hook(\n            channel=\"on_step\",\n            hook=HookContext.from_callable(\n                before=self._on_step_begin, after=self._on_step_end\n            ),\n        )\n\n        # Register epoch-level hooks\n        self.register_hook(\n            channel=\"on_epoch\",\n            hook=HookContext.from_callable(\n                before=self._on_epoch_begin, after=self._on_epoch_end\n            ),\n        )\n\n        logger.info(\n            f\"MyHook instance created with step_freq={self.cfg.log_step_freq}, epoch_freq={self.cfg.log_epoch_freq}\"\n        )\n\n    def _on_loop_begin(self, args: PipelineHookArgs):\n        logger.info(\"Begining loop\")\n\n    def _on_loop_end(self, args: PipelineHookArgs):\n        logger.info(\"Ended loop\")\n\n    def _on_step_begin(self, args: PipelineHookArgs):\n        # Note: step_id is 0-indexed. Adding 1 for 1-indexed frequency check.\n        if (args.step_id + 1) % self.cfg.log_step_freq == 0:\n            logger.info(\"Begining {}-th step\".format(args.step_id))\n\n    def _on_step_end(self, args: PipelineHookArgs):\n        if (args.step_id + 1) % self.cfg.log_step_freq == 0:\n            logger.info(\"Ended {}-th step\".format(args.step_id))\n\n    def _on_epoch_begin(self, args: PipelineHookArgs):\n        # Note: epoch_id is 0-indexed. Adding 1 for 1-indexed frequency check.\n        if (args.epoch_id + 1) % self.cfg.log_epoch_freq == 0:\n            logger.info(\"Begining {}-th epoch\".format(args.epoch_id))\n\n    def _on_epoch_end(self, args: PipelineHookArgs):\n        if (args.epoch_id + 1) % self.cfg.log_epoch_freq == 0:\n            logger.info(\"Ended {}-th epoch\".format(args.epoch_id))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Defining Your Custom Hook Configuration\n\nThen, we define a Pydantic configuration class for our custom hook.\nThis class will inherit from ``PipelineHooksConfig`` and specify our custom hook\nclass as its ``class_type``. It will also hold any parameters our hook needs,\nlike logging frequencies.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class MyHookConfig(PipelineHooksConfig[MyHook]):\n    class_type: type[MyHook] = MyHook\n    log_step_freq: int = 5\n    log_epoch_freq: int = 1\n\n\nmy_hook = MyHookConfig()\n\nhooks.append(my_hook)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### DataLoader, model, optimizer and learning rate scheduler\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torch.optim import SGD\nfrom torch.optim.lr_scheduler import StepLR\n\ntrain_dataset, _ = cfg.dataset.get_dataset()\ntrain_dataloader = DataLoader(\n    train_dataset,\n    batch_size=cfg.batch_size,\n    shuffle=True,\n    num_workers=cfg.num_workers,\n    pin_memory=False,\n)\n\nmodel = models.resnet50()\n\noptimizer = SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\nlr_scheduler = StepLR(optimizer, step_size=30, gamma=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part3: Orchestrating the Training\n\n:py:class:`robo_orchard_lab.pipeline.hook_based_trainer.HookBasedTrainer` is the heart of your training loop.\nIt takes all necessary PyTorch components (model, dataloader, optimizer, scheduler) and crucially,\nthe accelerator and a batch_processor. The hooks list allows for powerful customization, which we have explored before.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from robo_orchard_lab.pipeline import HookBasedTrainer\n\ntrainer = HookBasedTrainer(\n    model=model,\n    dataloader=train_dataloader,\n    optimizer=optimizer,\n    lr_scheduler=lr_scheduler,\n    accelerator=accelerator,\n    batch_processor=MyBatchProcessor(need_backward=True),\n    max_epoch=cfg.max_epoch,\n    hooks=hooks,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Show hooks\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(trainer.hooks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Begin training\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "trainer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "All the checkpoints is saved to ``cfg.workspace``\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import subprocess\n\nprint(subprocess.check_output([\"tree\", cfg.workspace_root]).decode())"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}