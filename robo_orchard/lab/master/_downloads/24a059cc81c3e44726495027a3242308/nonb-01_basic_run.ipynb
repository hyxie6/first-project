{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Configuration & Your First Basic Training Run\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prerequest: Import packages and configure logging\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import logging\nimport os\nfrom typing import Any, Optional, Tuple\n\nimport torch\n\nfrom robo_orchard_lab.utils import log_basic_config\n\nlog_basic_config(level=logging.INFO)\nlogger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using pydantic for configuration\nOur framework emphasizes configuration-driven training. Let's look at DatasetConfig\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pydantic import Field\nfrom robo_orchard_core.utils.cli import SettingConfig\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import datasets, models, transforms\n\n\nclass DatasetConfig(SettingConfig):\n    \"\"\"Configuration for the dataset.\n\n    This is a example configuration for the ImageNet dataset.\n    \"\"\"\n\n    data_root: Optional[str] = Field(\n        description=\"Image dataset directory.\", default=None\n    )\n\n    pipeline_test: bool = Field(\n        description=\"Whether or not use dummy data for fast pipeline test.\",\n        default=False,\n    )\n\n    dummy_train_imgs: int = Field(\n        description=\"Number of dummy training images.\",\n        default=1024,\n    )\n\n    dummy_val_imgs: int = Field(\n        description=\"Number of dummy validation images.\",\n        default=256,\n    )\n\n    def __post_init__(self):\n        if self.pipeline_test is False and self.data_root is None:\n            raise ValueError(\n                \"data_root must be specified when pipeline_test is False.\"\n            )\n\n    def get_dataset(self) -> Tuple[Dataset, Dataset]:\n        if self.pipeline_test:\n            train_dataset = datasets.FakeData(\n                self.dummy_train_imgs,\n                (3, 224, 224),\n                1000,\n                transforms.ToTensor(),\n            )\n            val_dataset = datasets.FakeData(\n                self.dummy_val_imgs, (3, 224, 224), 1000, transforms.ToTensor()\n            )\n        else:\n            assert self.data_root is not None\n            train_dataset = datasets.ImageFolder(\n                os.path.join(self.data_root, \"train\"),\n                transform=transforms.Compose(\n                    [\n                        transforms.RandomResizedCrop(224),\n                        transforms.RandomHorizontalFlip(),\n                        transforms.ToTensor(),\n                        transforms.Normalize(\n                            mean=[0.485, 0.456, 0.406],\n                            std=[0.229, 0.224, 0.225],\n                        ),\n                    ]\n                ),\n            )\n\n            val_dataset = datasets.ImageFolder(\n                os.path.join(self.data_root, \"val\"),\n                transform=transforms.Compose(\n                    [\n                        transforms.Resize(256),\n                        transforms.CenterCrop(224),\n                        transforms.ToTensor(),\n                        transforms.Normalize(\n                            mean=[0.485, 0.456, 0.406],\n                            std=[0.229, 0.224, 0.225],\n                        ),\n                    ]\n                ),\n            )\n        return train_dataset, val_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "DatasetConfig uses Pydantic Field to define parameters like data_root and pipeline_test.\nThe pipeline_test flag is crucial. If True, it uses FakeData for a quick test run without needing the actual ImageNet dataset.\nget_dataset() method encapsulates the logic for creating train and validation datasets.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "TrainerConfig, which nests DatasetConfig:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class TrainerConfig(SettingConfig):\n    \"\"\"Configuration for the trainer.\n\n    This is an example configuration for training a ResNet50 model\n    on ImageNet. Only a few parameters are set here for demonstration\n    purposes.\n    \"\"\"\n\n    dataset: DatasetConfig = Field(\n        description=\"Dataset configuration. Need to be set by user.\",\n    )\n\n    batch_size: int = Field(\n        description=\"Batch size for training.\",\n        default=128,\n    )\n\n    num_workers: int = Field(\n        description=\"Number of workers for data loading.\",\n        default=4,\n    )\n\n    max_epoch: int = Field(\n        description=\"Maximum number of epochs for training.\",\n        default=90,\n    )\n\n    workspace_root: str = Field(\n        description=\"Workspace root directory.\",\n        default=\"./workspace/\",\n    )\n\n\ncfg = TrainerConfig(\n    dataset=DatasetConfig(pipeline_test=True), max_epoch=5, num_workers=0,\n    workspace_root=\"./workspace/tutorial1/\"\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These Pydantic models can also parsed from command-line arguments using ``pydantic_from_argparse(TrainerConfig, parser)``. This means you can override any setting from the CLI, e.g., ``--batch_size 64`` or even nested ones like ``--dataset.data_root /path/to/my/data``.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Understanding the Core trainer Components\nLet's dive into the specific components from robo_orchard_lab that make this work.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Accelerator: The Engine for Scale and Simplicity\nAccelerator from Hugging Face handles:\n\n* Device Agnosticism: Runs your code on CPU, single GPU, multiple GPUs, or TPUs with minimal changes.\n\n* Distributed Training: Automatically sets up distributed training if multiple GPUs are available.\n\n* Mixed Precision: Can enable AMP for faster training and reduced memory.\n\n* Checkpointing: Accelerator manage saving and loading checkpoints in an organized way.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from accelerate import Accelerator\nfrom accelerate.utils import ProjectConfiguration\n\naccelerator = Accelerator(\n    project_config=ProjectConfiguration(\n        project_dir=cfg.workspace_root,\n        logging_dir=os.path.join(cfg.workspace_root, \"logs\"),\n        automatic_checkpoint_naming=True,\n        total_limit=32,  # Max checkpoints to keep\n    )\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Batch processor: Defining Per-Step Logic\nInstead of hard coding the forward pass and loss calculation within the trainer, we use a BatchProcessor.\nMyBatchProcessor inherits from :py:class:`~robo_orchard_lab.pipeline.batch_processor.simple.SimpleBatchProcessor`.\n\nYou define your loss function (here, CrossEntropyLoss) in ``__init__``.\n``forward`` contains the logic for a single step: getting model output and calculating loss.\nThe need_backward flag allows this processor to be used for evaluation loops where backpropagation isn't needed.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>Accelerator handles moving the model and batch to the correct device before forward is called by the trainer.</p></div>\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from robo_orchard_lab.pipeline.batch_processor import SimpleBatchProcessor\n\n\nclass MyBatchProcessor(SimpleBatchProcessor):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.criterion = torch.nn.CrossEntropyLoss()  # Define your loss\n\n    def forward(\n        self,\n        model: torch.nn.Module,\n        batch: Tuple[torch.Tensor, torch.Tensor],\n    ) -> Tuple[Any, Optional[torch.Tensor]]:\n        # unpack batch by yourself\n        images, target = batch\n\n        # Accelerator has already moved batch to the correct device\n        output = model(images)\n        loss = self.criterion(output, target) if self.need_backward else None\n\n        return output, loss  # Returns model output and loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hooks: Customizing your pipeline\nHooks are the primary way to add custom behavior to the training or evaluation loop without modifying its source code.\nThey are called at specific points during training or evaluation (e.g., end of epoch, after a step).\n\nFor more details please visit the next tutorial, in this tutorial, we will only use the StatsMonitor hook for logging.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "hooks = []\n\nfrom robo_orchard_lab.pipeline.hooks import StatsMonitorConfig\n\nstats = StatsMonitorConfig(step_log_freq=64)\n\nhooks.append(stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### DataLoader, model, optimizer and learning rate scheduler\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torch.optim import SGD\nfrom torch.optim.lr_scheduler import StepLR\n\ntrain_dataset, _ = cfg.dataset.get_dataset()\ntrain_dataloader = DataLoader(\n    train_dataset,\n    batch_size=cfg.batch_size,\n    shuffle=True,\n    num_workers=cfg.num_workers,\n    pin_memory=False,\n)\n\nmodel = models.resnet50()\n\noptimizer = SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\nlr_scheduler = StepLR(optimizer, step_size=30, gamma=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Orchestrating the Training\n\n:py:class:`~robo_orchard_lab.pipeline.hook_based_trainer.HookBasedTrainer` is the heart of your training loop.\nIt takes all necessary PyTorch components (model, dataloader, optimizer, scheduler) and crucially,\nthe accelerator and a batch_processor. The hooks list allows for powerful customization, which we have explored before.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from robo_orchard_lab.pipeline import HookBasedTrainer\n\ntrainer = HookBasedTrainer(\n    model=model,\n    dataloader=train_dataloader,\n    optimizer=optimizer,\n    lr_scheduler=lr_scheduler,\n    accelerator=accelerator,\n    batch_processor=MyBatchProcessor(need_backward=True),\n    max_epoch=cfg.max_epoch,\n    hooks=hooks,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Begin training\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "trainer()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}