
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "build/trainer_tutorial/nonb-02_built_in_hooks.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_build_trainer_tutorial_nonb-02_built_in_hooks.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_build_trainer_tutorial_nonb-02_built_in_hooks.py:

Leveraging Built-in Hooks for Common Training Tasks
==========================================================

Hooks are the primary way to add custom behavior to the training or evaluation loop without modifying its source code.
They are called at specific points during training or evaluation (e.g., end of epoch, after a step).

.. GENERATED FROM PYTHON SOURCE LINES 27-30

Reuse the code from previous tutorial
------------------------------------------------------


.. GENERATED FROM PYTHON SOURCE LINES 30-217

.. code-block:: Python


    import logging
    import os
    from typing import Any, Optional, Tuple

    import torch

    from robo_orchard_lab.utils import log_basic_config

    log_basic_config(level=logging.INFO)
    logger = logging.getLogger(__name__)

    from pydantic import Field
    from robo_orchard_core.utils.cli import SettingConfig
    from torch.utils.data import DataLoader, Dataset
    from torchvision import datasets, models, transforms


    class DatasetConfig(SettingConfig):
        """Configuration for the dataset.

        This is a example configuration for the ImageNet dataset.
        """

        data_root: Optional[str] = Field(
            description="Image dataset directory.", default=None
        )

        pipeline_test: bool = Field(
            description="Whether or not use dummy data for fast pipeline test.",
            default=False,
        )

        dummy_train_imgs: int = Field(
            description="Number of dummy training images.",
            default=1024,
        )

        dummy_val_imgs: int = Field(
            description="Number of dummy validation images.",
            default=256,
        )

        def __post_init__(self):
            if self.pipeline_test is False and self.data_root is None:
                raise ValueError(
                    "data_root must be specified when pipeline_test is False."
                )

        def get_dataset(self) -> Tuple[Dataset, Dataset]:
            if self.pipeline_test:
                train_dataset = datasets.FakeData(
                    self.dummy_train_imgs,
                    (3, 224, 224),
                    1000,
                    transforms.ToTensor(),
                )
                val_dataset = datasets.FakeData(
                    self.dummy_val_imgs, (3, 224, 224), 1000, transforms.ToTensor()
                )
            else:
                assert self.data_root is not None
                train_dataset = datasets.ImageFolder(
                    os.path.join(self.data_root, "train"),
                    transform=transforms.Compose(
                        [
                            transforms.RandomResizedCrop(224),
                            transforms.RandomHorizontalFlip(),
                            transforms.ToTensor(),
                            transforms.Normalize(
                                mean=[0.485, 0.456, 0.406],
                                std=[0.229, 0.224, 0.225],
                            ),
                        ]
                    ),
                )

                val_dataset = datasets.ImageFolder(
                    os.path.join(self.data_root, "val"),
                    transform=transforms.Compose(
                        [
                            transforms.Resize(256),
                            transforms.CenterCrop(224),
                            transforms.ToTensor(),
                            transforms.Normalize(
                                mean=[0.485, 0.456, 0.406],
                                std=[0.229, 0.224, 0.225],
                            ),
                        ]
                    ),
                )
            return train_dataset, val_dataset


    class TrainerConfig(SettingConfig):
        """Configuration for the trainer.

        This is an example configuration for training a ResNet50 model
        on ImageNet. Only a few parameters are set here for demonstration
        purposes.
        """

        dataset: DatasetConfig = Field(
            description="Dataset configuration. Need to be set by user.",
        )

        batch_size: int = Field(
            description="Batch size for training.",
            default=128,
        )

        num_workers: int = Field(
            description="Number of workers for data loading.",
            default=4,
        )

        max_epoch: int = Field(
            description="Maximum number of epochs for training.",
            default=90,
        )

        workspace_root: str = Field(
            description="Workspace root directory.",
            default="./workspace/",
        )


    cfg = TrainerConfig(
        dataset=DatasetConfig(pipeline_test=True), max_epoch=5, num_workers=0,
        workspace_root="./workspace/tutorial2/"
    )

    from accelerate import Accelerator
    from accelerate.utils import ProjectConfiguration

    accelerator = Accelerator(
        project_config=ProjectConfiguration(
            project_dir=cfg.workspace_root,
            logging_dir=os.path.join(cfg.workspace_root, "logs"),
            automatic_checkpoint_naming=True,
            total_limit=32,  # Max checkpoints to keep
        )
    )


    from robo_orchard_lab.pipeline.batch_processor import SimpleBatchProcessor


    class MyBatchProcessor(SimpleBatchProcessor):
        def __init__(self, *args, **kwargs):
            super().__init__(*args, **kwargs)
            self.criterion = torch.nn.CrossEntropyLoss()  # Define your loss

        def forward(
            self,
            model: torch.nn.Module,
            batch: Tuple[torch.Tensor, torch.Tensor],
        ) -> Tuple[Any, Optional[torch.Tensor]]:
            # unpack batch by yourself
            images, target = batch

            # Accelerator has already moved batch to the correct device
            output = model(images)
            loss = self.criterion(output, target) if self.need_backward else None

            return output, loss  # Returns model output and loss


    from torch.optim import SGD
    from torch.optim.lr_scheduler import StepLR

    train_dataset, _ = cfg.dataset.get_dataset()
    train_dataloader = DataLoader(
        train_dataset,
        batch_size=cfg.batch_size,
        shuffle=True,
        num_workers=cfg.num_workers,
        pin_memory=False,
    )

    model = models.resnet50()

    optimizer = SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)
    lr_scheduler = StepLR(optimizer, step_size=30, gamma=0.1)

    hooks = []








.. GENERATED FROM PYTHON SOURCE LINES 218-233

Core concepts of the hook System
------------------------------------------------------------------------

* :py:class:`~robo_orchard_lab.pipeline.hooks.mixin.PipelineHookArgs`: A dataclass holding all relevant information (accelerator,
  epoch/step IDs, batch data, model outputs, loss, etc.) passed to each hook.
  This ensures hooks have a standardized, type-safe context.

* :py:class:`~robo_orchard_lab.pipeline.hooks.mixin.PipelineHooksConfig`: The entire :py:class:`~robo_orchard_lab.pipeline.hooks.mixin.PipelineHooks` setup,
  including which individual hooks are active and their parameters, can often be defined via Pydantic configurations.
  This offers great flexibility and reproducibility. For instance, a main
  experiment config might point to a :py:class:`~robo_orchard_lab.pipeline.hooks.mixin.PipelineHooksConfig`,
  which in turn might specify a list of individual hook configurations (e.g.,
  :py:class:`~robo_orchard_lab.pipeline.hooks.metric.MetricTrackerConfig`,
  :py:class:`~robo_orchard_lab.pipeline.hooks.checkpoint.SaveCheckpointConfig`).


.. GENERATED FROM PYTHON SOURCE LINES 235-257

Some built-in hooks
------------------------------------------------------------------------

To streamline common training tasks and reduce boilerplate code, **robo_orchard_lab**
provides a collection of pre-built hooks. These hooks are implemented using the same
underlying :py:class:`~robo_orchard_lab.pipeline.hooks.mixin.PipelineHooks` and
:py:class:`~robo_orchard_lab.pipeline.hooks.mixin.HookContext` mechanisms discussed
previously.

Typically, you interact with these built-in hooks by instantiating their
corresponding Pydantic configuration classes (e.g., ``MetricTrackerConfig``,
``StatsMonitorConfig``, ``SaveCheckpointConfig``). These config objects allow you
to customize the behavior of the hook and are then used to create the actual
hook instances, which are subsequently added to your main ``HookBasedTrainer``'s
list of active hooks.

In the following subsections, we will explore how to configure and use some of
the most common built-in hooks provided by the framework. While these cover
frequent use cases, remember that you can always create your own custom hooks
(as shown in the "(Advanced) Creating Your First Custom Hook" section) for more
specialized requirements.


.. GENERATED FROM PYTHON SOURCE LINES 259-271

MetricTracker: Track on performance
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
:py:class:`~robo_orchard_lab.pipeline.hooks.metric.MetricTracker` is a specialized hook for handling metrics.
It takes a list of :py:class:`~robo_orchard_lab.pipeline.hooks.metric.MetricEntry` objects. Each MetricEntry defines:

* names: How the metric will be logged.

* metric: An instance of a torchmetrics metric (or any compatible metric object).

:py:class:`~robo_orchard_lab.pipeline.hooks.metric.MetricTracker` is an abstarct class, you should inherit it
and implement the :py:meth:`~robo_orchard_lab.pipeline.hooks.metric.MetricTracker.update_metric` method, which is called by the trainer to update these metrics with batch outputs and targets.


.. GENERATED FROM PYTHON SOURCE LINES 271-317

.. code-block:: Python


    from torchmetrics import Accuracy as AccuracyMetric

    from robo_orchard_lab.pipeline.hooks import (
        MetricEntry,
        MetricTracker,
        MetricTrackerConfig,
    )


    class MyMetricTracker(MetricTracker):
        def update_metric(self, batch: Any, model_outputs: Any):
            _, targets = batch
            for metric_i in self.metrics:
                metric_i(model_outputs, targets)


    class MyMetricTrackerConfig(MetricTrackerConfig):
        """An example metric tracker config."""

        # note: bind MyMetricTracker
        class_type: type[MyMetricTracker] = MyMetricTracker


    metric_tracker = MyMetricTrackerConfig(
        metric_entrys=[
            MetricEntry(
                names=["top1_acc"],
                metric=AccuracyMetric(
                    task="multiclass", num_classes=1000, top_k=1
                ),
            ),
            MetricEntry(
                names=["top5_acc"],
                metric=AccuracyMetric(
                    task="multiclass", num_classes=1000, top_k=5
                ),
            ),
        ],
        step_log_freq=64,
        log_main_process_only=False,
    )

    hooks.append(metric_tracker)









.. GENERATED FROM PYTHON SOURCE LINES 318-324

StatsMonitor: Logging Training Vitals
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

:py:class:`~robo_orchard_lab.pipeline.hooks.stats.StatsMonitor` monitors and logs statistics like learning rate, training speed (samples/sec), estimated time remaining, etc.
Its ``step_log_freq`` controls how often this information is printed or logged.


.. GENERATED FROM PYTHON SOURCE LINES 324-331

.. code-block:: Python


    from robo_orchard_lab.pipeline.hooks import StatsMonitorConfig

    stats = StatsMonitorConfig(step_log_freq=64)

    hooks.append(stats)








.. GENERATED FROM PYTHON SOURCE LINES 332-339

SaveCheckpoint: Saving Your Progress
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

:py:class:`~robo_orchard_lab.pipeline.hooks.checkpoint.SaveCheckpointConfig` is responsible for triggering model checkpoint saves.
It calls :py:class:`~acclerator.Accelerator.save_state()`` internally. ``save_step_freq`` defines how many training steps between checkpoints.
Resuming is handled by Accelerator


.. GENERATED FROM PYTHON SOURCE LINES 339-346

.. code-block:: Python


    from robo_orchard_lab.pipeline.hooks import SaveCheckpointConfig

    save_checkpoint = SaveCheckpointConfig(save_step_freq=1024)

    hooks.append(save_checkpoint)








.. GENERATED FROM PYTHON SOURCE LINES 347-350

Orchestrating the Training
------------------------------------------------------------------------


.. GENERATED FROM PYTHON SOURCE LINES 350-364

.. code-block:: Python


    from robo_orchard_lab.pipeline import HookBasedTrainer

    trainer = HookBasedTrainer(
        model=model,
        dataloader=train_dataloader,
        optimizer=optimizer,
        lr_scheduler=lr_scheduler,
        accelerator=accelerator,
        batch_processor=MyBatchProcessor(need_backward=True),
        max_epoch=cfg.max_epoch,
        hooks=hooks,
    )








.. GENERATED FROM PYTHON SOURCE LINES 365-367

Show hooks


.. GENERATED FROM PYTHON SOURCE LINES 367-370

.. code-block:: Python


    print(trainer.hooks)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    <robo_orchard_lab.pipeline.hooks.mixin.PipelineHooks(
      hooks={
        on_loop: <robo_orchard_core.utils.hook.HookContextChannel(
          name=on_loop, 
          hooks=[
            0: <robo_orchard_core.utils.hook.HookContextFromCallable(
              name=None, 
              before=<FunctionInfo bound method MyMetricTracker(id=140335706835120)._on_loop_begin from ../../robo_orchard_lab/pipeline/hooks/metric.py:181>, 
              after=None)>,
            1: <robo_orchard_core.utils.hook.HookContextFromCallable(
              name=None, 
              before=<FunctionInfo bound method StatsMonitor(id=140335706833824)._on_loop_begin from ../../robo_orchard_lab/pipeline/hooks/stats.py:234>, 
              after=None)>
          ])>, 
        on_epoch: <robo_orchard_core.utils.hook.HookContextChannel(
          name=on_epoch, 
          hooks=[
            0: <robo_orchard_core.utils.hook.HookContextFromCallable(
              name=None, 
              before=None, 
              after=<FunctionInfo bound method MyMetricTracker(id=140335706835120)._on_epoch_end from ../../robo_orchard_lab/pipeline/hooks/metric.py:233>)>,
            1: <robo_orchard_core.utils.hook.HookContextFromCallable(
              name=None, 
              before=<FunctionInfo bound method StatsMonitor(id=140335706833824)._on_epoch_begin from ../../robo_orchard_lab/pipeline/hooks/stats.py:316>, 
              after=<FunctionInfo bound method StatsMonitor(id=140335706833824)._on_epoch_end from ../../robo_orchard_lab/pipeline/hooks/stats.py:321>)>,
            2: <robo_orchard_core.utils.hook.HookContextFromCallable(
              name=None, 
              before=None, 
              after=<FunctionInfo bound method SaveCheckpoint(id=140335706841168)._on_epoch_end from ../../robo_orchard_lab/pipeline/hooks/checkpoint.py:116>)>
          ])>, 
        on_step: <robo_orchard_core.utils.hook.HookContextChannel(
          name=on_step, 
          hooks=[
            0: <robo_orchard_core.utils.hook.HookContextFromCallable(
              name=None, 
              before=None, 
              after=<FunctionInfo bound method OptimizerHook(id=140335706841072)._optimizer_step from ../../robo_orchard_lab/pipeline/hooks/optimizer.py:45>)>,
            1: <robo_orchard_core.utils.hook.HookContextFromCallable(
              name=None, 
              before=None, 
              after=<FunctionInfo bound method MyMetricTracker(id=140335706835120)._on_step_end from ../../robo_orchard_lab/pipeline/hooks/metric.py:205>)>,
            2: <robo_orchard_core.utils.hook.HookContextFromCallable(
              name=None, 
              before=<FunctionInfo bound method StatsMonitor(id=140335706833824)._on_step_begin from ../../robo_orchard_lab/pipeline/hooks/stats.py:245>, 
              after=<FunctionInfo bound method StatsMonitor(id=140335706833824)._on_step_end from ../../robo_orchard_lab/pipeline/hooks/stats.py:249>)>,
            3: <robo_orchard_core.utils.hook.HookContextFromCallable(
              name=None, 
              before=None, 
              after=<FunctionInfo bound method SaveCheckpoint(id=140335706841168)._on_step_end from ../../robo_orchard_lab/pipeline/hooks/checkpoint.py:88>)>
          ])>, 
        on_batch: <robo_orchard_core.utils.hook.HookContextChannel(
          name=on_batch, 
          hooks=[
            0: <robo_orchard_core.utils.hook.HookContextFromCallable(
              name=None, 
              before=None, 
              after=<FunctionInfo bound method MyMetricTracker(id=140335706835120)._on_batch_end from ../../robo_orchard_lab/pipeline/hooks/metric.py:194>)>
          ])>, 
      })>




.. GENERATED FROM PYTHON SOURCE LINES 371-373

Begin training


.. GENERATED FROM PYTHON SOURCE LINES 373-377

.. code-block:: Python


    trainer()









.. GENERATED FROM PYTHON SOURCE LINES 378-379

All the checkpoints is saved to ``cfg.workspace``

.. GENERATED FROM PYTHON SOURCE LINES 379-383

.. code-block:: Python


    import subprocess

    print(subprocess.check_output(["tree", cfg.workspace_root]).decode())




.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    ./workspace/tutorial2/
    └── checkpoints
        ├── checkpoint_0
        │   ├── custom_checkpoint_0.pkl
        │   ├── model_1.safetensors
        │   ├── model.safetensors
        │   ├── optimizer.bin
        │   ├── random_states_0.pkl
        │   └── scheduler.bin
        ├── checkpoint_1
        │   ├── custom_checkpoint_0.pkl
        │   ├── model_1.safetensors
        │   ├── model.safetensors
        │   ├── optimizer.bin
        │   ├── random_states_0.pkl
        │   └── scheduler.bin
        ├── checkpoint_2
        │   ├── custom_checkpoint_0.pkl
        │   ├── model_1.safetensors
        │   ├── model.safetensors
        │   ├── optimizer.bin
        │   ├── random_states_0.pkl
        │   └── scheduler.bin
        ├── checkpoint_3
        │   ├── custom_checkpoint_0.pkl
        │   ├── model_1.safetensors
        │   ├── model.safetensors
        │   ├── optimizer.bin
        │   ├── random_states_0.pkl
        │   └── scheduler.bin
        └── checkpoint_4
            ├── custom_checkpoint_0.pkl
            ├── model_1.safetensors
            ├── model.safetensors
            ├── optimizer.bin
            ├── random_states_0.pkl
            └── scheduler.bin

    6 directories, 30 files






.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 21.664 seconds)


.. _sphx_glr_download_build_trainer_tutorial_nonb-02_built_in_hooks.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: nonb-02_built_in_hooks.ipynb <nonb-02_built_in_hooks.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: nonb-02_built_in_hooks.py <nonb-02_built_in_hooks.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: nonb-02_built_in_hooks.zip <nonb-02_built_in_hooks.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
